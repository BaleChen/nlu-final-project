{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f30c4de-6154-48bd-b006-c75b2c94f655",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import transformers\n",
    "import numpy as np\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "500675a7-b39e-4c30-9cf9-b0509ecb9da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"gpt2-xl\", \"EleutherAI/gpt-neo-2.7B\", \"EleutherAI/gpt-j-6B\", \"EleutherAI/gpt-neox-20b\"]\n",
    "dataset = [\"xsum\", \"squad\", \"writing\"] # squad needs dataset key \"context\"\n",
    "\n",
    "template = \"\"\"#!/bin/bash\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --cpus-per-task=4\n",
    "#SBATCH --job-name={}-{}-bl\n",
    "#SBATCH --output=/scratch/bc3088/nlu/detect-gpt/log/%j_%x.out\n",
    "#SBATCH --error=/scratch/bc3088/nlu/detect-gpt/log/%j_%x.err\n",
    "#SBATCH --time=12:00:00\n",
    "#SBATCH --gres=gpu:1\n",
    "#SBATCH --mem=60G\n",
    "#SBATCH --requeue\n",
    "\n",
    "#SBATCH --mail-type=ALL\n",
    "#SBATCH --mail-user=bale.chen@nyu.edu\n",
    "\n",
    "module purge\n",
    "\n",
    "singularity exec --nv --bind /scratch/bc3088/ --overlay /scratch/bc3088/nlu/detect-gpt/overlay-25GB-500K.ext3:ro /scratch/work/public/singularity/cuda11.4.2-cudnn8.2.4-devel-ubuntu20.04.3.sif /bin/bash -c \"\n",
    "source /ext3/env.sh;\n",
    "conda activate; \n",
    "{}\\\"\n",
    "\"\"\"\n",
    "\n",
    "for m in models:\n",
    "    for d in dataset:\n",
    "        s = f\"python run-small.py --dataset {d} --n_samples 500 --n_perturbation_list 50 --base_model_name {m} --mask_filling_model_name t5-3b --perturb_method detectgpt --pct_words_masked 0.3 --span_length 2 --batch_size 4 --half\"\n",
    "        if d == \"squad\":\n",
    "            s += \" --dataset_key context\"\n",
    "        m_ = m.replace(\"/\", \"_\")\n",
    "        fname = f\"baseline-slurms/{m_}-{d}-baseline.sh\"\n",
    "        with open(fname, \"w\") as f:\n",
    "            f.write(template.format(m_, d, s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "102e873a-e9fc-4b28-870a-9d0f3811affb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sbatch baseline-slurms/EleutherAI_gpt-neo-2.7B-squad-baseline.sh\n",
      "sbatch baseline-slurms/EleutherAI_gpt-neo-2.7B-writing-baseline.sh\n",
      "sbatch baseline-slurms/EleutherAI_gpt-j-6B-squad-baseline.sh\n",
      "sbatch baseline-slurms/EleutherAI_gpt-j-6B-writing-baseline.sh\n",
      "sbatch baseline-slurms/EleutherAI_gpt-neox-20b-squad-baseline.sh\n",
      "sbatch baseline-slurms/EleutherAI_gpt-neox-20b-writing-baseline.sh\n"
     ]
    }
   ],
   "source": [
    "dataset = [\"squad\", \"writing\"]\n",
    "models = [\"EleutherAI/gpt-neo-2.7B\", \"EleutherAI/gpt-j-6B\", \"EleutherAI/gpt-neox-20b\"]\n",
    "for m in models:\n",
    "    for d in dataset:\n",
    "        m = m.replace(\"/\", \"_\")\n",
    "        fname = f\"baseline-slurms/{m}-{d}-baseline.sh\"\n",
    "        print(\"sbatch\", fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffba1479-bec2-4c3d-8f3c-307048141237",
   "metadata": {},
   "outputs": [],
   "source": [
    "python run-small.py \n",
    "--dataset xsum \n",
    "--n_samples 500 \n",
    "--n_perturbation_list 50\n",
    "--base_model_name gpt2-xl\n",
    "--perturb_method noise_embed \n",
    "--noisy_level 0.3 \n",
    "--skip_baselines \n",
    "--batch_size 16 \n",
    "--pct_words_masked 0.3 \n",
    "--span_length 2 \n",
    "--half"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cdc4ea4e-b471-4fe8-b0f2-84f3328bc82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"gpt2-xl\", \"EleutherAI/gpt-neo-2.7B\", \"EleutherAI/gpt-j-6B\", \"EleutherAI/gpt-neox-20b\"]\n",
    "dataset = [\"xsum\", \"squad\", \"writing\"] # squad needs dataset key \"context\"\n",
    "\n",
    "template = \"\"\"#!/bin/bash\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --cpus-per-task=4\n",
    "#SBATCH --job-name={}-{}-cross\n",
    "#SBATCH --output=/scratch/bc3088/nlu/detect-gpt/log/%j_%x.out\n",
    "#SBATCH --error=/scratch/bc3088/nlu/detect-gpt/log/%j_%x.err\n",
    "#SBATCH --time=32:00:00\n",
    "#SBATCH --gres=gpu:rtx8000:1\n",
    "#SBATCH --mem=80G\n",
    "#SBATCH --requeue\n",
    "\n",
    "#SBATCH --mail-type=ALL\n",
    "#SBATCH --mail-user=bale.chen@nyu.edu\n",
    "\n",
    "module purge\n",
    "\n",
    "singularity exec --nv --bind /scratch/bc3088/ --overlay /scratch/bc3088/nlu/detect-gpt/overlay-25GB-500K.ext3:ro /scratch/work/public/singularity/cuda11.4.2-cudnn8.2.4-devel-ubuntu20.04.3.sif /bin/bash -c \"\n",
    "source /ext3/env.sh;\n",
    "conda activate; \n",
    "{}\\\"\n",
    "\"\"\"\n",
    "\n",
    "for m in models:\n",
    "    ensemble = []\n",
    "    for m2 in models:\n",
    "        if m2 != m:\n",
    "            ensemble.append(m2)\n",
    "    ensemble = \",\".join(ensemble)\n",
    "    for d in dataset:\n",
    "        s = f\"python run_v2.py --dataset {d} --n_samples 200 --n_perturbation_list 50 --base_model_name {m} --mask_filling_model_name t5-3b --ensemble_scoring {ensemble} --skip_baselines --pct_words_masked 0.3 --span_length 2 --batch_size 4 --half\"\n",
    "        if d == \"squad\":\n",
    "            s += \" --dataset_key context\"\n",
    "        m_ = m.replace(\"/\", \"_\")\n",
    "        fname = f\"cross-slurms/{m_}-{d}-cross.sh\"\n",
    "        with open(fname, \"w\") as f:\n",
    "            f.write(template.format(m_, d, s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5478fa3-5948-4c72-a58f-b8039641620e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sbatch cross-slurms/gpt2-xl-xsum-cross.sh\n",
      "sbatch cross-slurms/gpt2-xl-squad-cross.sh\n",
      "sbatch cross-slurms/gpt2-xl-writing-cross.sh\n",
      "sbatch cross-slurms/EleutherAI_gpt-neo-2.7B-xsum-cross.sh\n",
      "sbatch cross-slurms/EleutherAI_gpt-neo-2.7B-squad-cross.sh\n",
      "sbatch cross-slurms/EleutherAI_gpt-neo-2.7B-writing-cross.sh\n",
      "sbatch cross-slurms/EleutherAI_gpt-j-6B-xsum-cross.sh\n",
      "sbatch cross-slurms/EleutherAI_gpt-j-6B-squad-cross.sh\n",
      "sbatch cross-slurms/EleutherAI_gpt-j-6B-writing-cross.sh\n",
      "sbatch cross-slurms/EleutherAI_gpt-neox-20b-xsum-cross.sh\n",
      "sbatch cross-slurms/EleutherAI_gpt-neox-20b-squad-cross.sh\n",
      "sbatch cross-slurms/EleutherAI_gpt-neox-20b-writing-cross.sh\n"
     ]
    }
   ],
   "source": [
    "dataset = [\"xsum\", \"squad\", \"writing\"]\n",
    "models = [\"gpt2-xl\", \"EleutherAI/gpt-neo-2.7B\", \"EleutherAI/gpt-j-6B\", \"EleutherAI/gpt-neox-20b\"]\n",
    "for m in models:\n",
    "    for d in dataset:\n",
    "        m = m.replace(\"/\", \"_\")\n",
    "        fname = f\"cross-slurms/{m}-{d}-cross.sh\"\n",
    "        print(\"sbatch\", fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b301b773-dee0-44fd-9e90-90ecc78be76d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sbatch generate_data.sh gpt2-xl\n",
      "sbatch generate_data.sh EleutherAI/gpt-neo-2.7B\n",
      "sbatch generate_data.sh EleutherAI/gpt-j-6B\n",
      "sbatch generate_data.sh EleutherAI/gpt-neox-20b\n"
     ]
    }
   ],
   "source": [
    "dataset = [\"squad\"]\n",
    "models = [\"gpt2-xl\", \"EleutherAI/gpt-neo-2.7B\", \"EleutherAI/gpt-j-6B\", \"EleutherAI/gpt-neox-20b\"]\n",
    "for d in dataset:\n",
    "    for m in models:\n",
    "        print(\"sbatch\", \"generate_data.sh\", m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aca1e994-5be6-4e93-876b-f375e5633361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sbatch -J opt-ft-gpt2 run_opt_ft.sh gpt2-xl\n",
      "sbatch -J opt-ft-gpt-neo run_opt_ft.sh EleutherAI/gpt-neo-2.7B\n",
      "sbatch -J opt-ft-gpt-j run_opt_ft.sh EleutherAI/gpt-j-6B\n",
      "sbatch -J opt-ft-neox run_opt_ft.sh EleutherAI/gpt-neox-20b\n"
     ]
    }
   ],
   "source": [
    "models = [\"gpt2-xl\", \"EleutherAI/gpt-neo-2.7B\", \"EleutherAI/gpt-j-6B\", \"EleutherAI/gpt-neox-20b\"]\n",
    "model_short = [\"gpt2\", \"gpt-neo\", \"gpt-j\", \"neox\"]\n",
    "for d in dataset:\n",
    "    for m, ms in zip(models, model_short):\n",
    "        print(\"sbatch -J\", f\"opt-ft-{ms}\", \"run_opt_ft.sh\", m)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7463c1a4-3adf-4d71-b2f5-206fb178271f",
   "metadata": {},
   "source": [
    "## OPT Scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49b946ce-9887-4ffa-86a7-74ad2b9b617c",
   "metadata": {},
   "outputs": [],
   "source": [
    "templete = \"\"\"#!/bin/bash\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --cpus-per-task=4\n",
    "#SBATCH --job-name=fo-{}-{}\n",
    "#SBATCH --output=/scratch/bc3088/nlu/detect-gpt/log/%j_%x.out\n",
    "#SBATCH --error=/scratch/bc3088/nlu/detect-gpt/log/%j_%x.err\n",
    "#SBATCH --time=5:00:00\n",
    "#SBATCH --gres=gpu:1\n",
    "#SBATCH --mem=50G\n",
    "#SBATCH --requeue\n",
    "\n",
    "#SBATCH --mail-type=ALL\n",
    "#SBATCH --mail-user=bc3088@nyu.edu\n",
    "\n",
    "module purge\n",
    "\n",
    "singularity exec --nv --bind /scratch/bc3088/ --overlay /scratch/bc3088/nlu/detect-gpt/overlay-25GB-500K.ext3:ro /scratch/work/public/singularity/cuda11.4.2-cudnn8.2.4-devel-ubuntu20.04.3.sif /bin/bash -c \"source /ext3/env.sh;\n",
    "conda activate;\n",
    "python run_v5.py --output_name fo --base_model_name {} --scoring_model_name facebook/opt-1.3b --mask_filling_model_name t5-3b --n_perturbation_list 50 --n_samples 200 --pct_words_masked 0.3 --span_length 2 --checkpoint_dir {} --ft-epoch {} --skip_baselines\n",
    "\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a306dd63-0ebc-40da-8866-2535fdea9094",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"checkpoint_dict.json\", \"rb\") as f:\n",
    "    cp_d = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb262888-31cd-40d4-bf42-113d2c8c8e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"gpt2-xl\", \"EleutherAI/gpt-neo-2.7B\", \"EleutherAI/gpt-j-6B\", \"EleutherAI/gpt-neox-20b\"]\n",
    "\n",
    "for m in models:\n",
    "    m_ = m.replace(\"/\", \"_\")\n",
    "    checkpoint_list = cp_d[m_]\n",
    "    for idx, cp in enumerate(checkpoint_list):\n",
    "        epoch = 2*(idx+1)\n",
    "        cp_path = f\"ft-opt/{m_}/{cp}\"\n",
    "        temp_templete = templete.format(epoch, m_, m, cp_path, epoch)\n",
    "        fname = f\"ft-opt-slurms/{m_}-ep{epoch}.sh\"\n",
    "        with open(fname, \"w\") as f:\n",
    "            f.write(temp_templete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99e41642-6f98-4a95-9ee8-3d9b240c2a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sbatch ft-opt-slurms/gpt2-xl-ep2.sh\n",
      "sbatch ft-opt-slurms/gpt2-xl-ep4.sh\n",
      "sbatch ft-opt-slurms/gpt2-xl-ep6.sh\n",
      "sbatch ft-opt-slurms/gpt2-xl-ep8.sh\n",
      "sbatch ft-opt-slurms/gpt2-xl-ep10.sh\n",
      "sbatch ft-opt-slurms/EleutherAI_gpt-neo-2.7B-ep2.sh\n",
      "sbatch ft-opt-slurms/EleutherAI_gpt-neo-2.7B-ep4.sh\n",
      "sbatch ft-opt-slurms/EleutherAI_gpt-neo-2.7B-ep6.sh\n",
      "sbatch ft-opt-slurms/EleutherAI_gpt-neo-2.7B-ep8.sh\n",
      "sbatch ft-opt-slurms/EleutherAI_gpt-neo-2.7B-ep10.sh\n",
      "sbatch ft-opt-slurms/EleutherAI_gpt-j-6B-ep2.sh\n",
      "sbatch ft-opt-slurms/EleutherAI_gpt-j-6B-ep4.sh\n",
      "sbatch ft-opt-slurms/EleutherAI_gpt-j-6B-ep6.sh\n",
      "sbatch ft-opt-slurms/EleutherAI_gpt-j-6B-ep8.sh\n",
      "sbatch ft-opt-slurms/EleutherAI_gpt-j-6B-ep10.sh\n",
      "sbatch ft-opt-slurms/EleutherAI_gpt-neox-20b-ep2.sh\n",
      "sbatch ft-opt-slurms/EleutherAI_gpt-neox-20b-ep4.sh\n",
      "sbatch ft-opt-slurms/EleutherAI_gpt-neox-20b-ep6.sh\n",
      "sbatch ft-opt-slurms/EleutherAI_gpt-neox-20b-ep8.sh\n",
      "sbatch ft-opt-slurms/EleutherAI_gpt-neox-20b-ep10.sh\n"
     ]
    }
   ],
   "source": [
    "for m in models:\n",
    "    m_ = m.replace(\"/\", \"_\")\n",
    "    for idx, cp in enumerate(checkpoint_list):\n",
    "        epoch = 2*(idx+1)\n",
    "        fname = f\"ft-opt-slurms/{m_}-ep{epoch}.sh\"\n",
    "        print(\"sbatch\", fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "57aa8350-5002-4759-ac55-db5372a8cbb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EleutherAI_gpt-j-6B, 6, xsum, 0.529\n",
      "EleutherAI_gpt-j-6B, 6, squad, 0.5112179487179487\n",
      "EleutherAI_gpt-j-6B, 6, writing, 0.571\n",
      "EleutherAI_gpt-j-6B, 2, xsum, 0.562\n",
      "EleutherAI_gpt-j-6B, 2, squad, 0.5480769230769231\n",
      "EleutherAI_gpt-j-6B, 2, writing, 0.643\n",
      "EleutherAI_gpt-j-6B, 8, xsum, 0.534\n",
      "EleutherAI_gpt-j-6B, 8, squad, 0.5192307692307693\n",
      "EleutherAI_gpt-j-6B, 8, writing, 0.552\n",
      "EleutherAI_gpt-j-6B, 4, xsum, 0.544\n",
      "EleutherAI_gpt-j-6B, 4, squad, 0.530448717948718\n",
      "EleutherAI_gpt-j-6B, 4, writing, 0.573\n",
      "EleutherAI_gpt-j-6B, 10, xsum, 0.539\n",
      "EleutherAI_gpt-j-6B, 10, squad, 0.5192307692307693\n",
      "EleutherAI_gpt-j-6B, 10, writing, 0.55\n",
      "EleutherAI_gpt-neox-20b, 6, xsum, 0.539\n",
      "EleutherAI_gpt-neox-20b, 6, squad, 0.530448717948718\n",
      "EleutherAI_gpt-neox-20b, 6, writing, 0.551\n",
      "EleutherAI_gpt-neox-20b, 4, xsum, 0.544\n",
      "EleutherAI_gpt-neox-20b, 4, squad, 0.5208333333333334\n",
      "EleutherAI_gpt-neox-20b, 4, writing, 0.556\n",
      "EleutherAI_gpt-neox-20b, 2, xsum, 0.539\n",
      "EleutherAI_gpt-neox-20b, 2, squad, 0.5464743589743589\n",
      "EleutherAI_gpt-neox-20b, 2, writing, 0.549\n",
      "EleutherAI_gpt-neox-20b, 8, xsum, 0.541\n",
      "EleutherAI_gpt-neox-20b, 8, squad, 0.5368589743589743\n",
      "EleutherAI_gpt-neox-20b, 8, writing, 0.525\n",
      "EleutherAI_gpt-neox-20b, 10, xsum, 0.534\n",
      "EleutherAI_gpt-neox-20b, 10, squad, 0.5384615384615384\n",
      "EleutherAI_gpt-neox-20b, 10, writing, 0.519\n",
      "gpt2-xl, 10, xsum, 0.525\n",
      "gpt2-xl, 10, squad, 0.5352564102564102\n",
      "gpt2-xl, 10, writing, 0.537\n",
      "gpt2-xl, 8, xsum, 0.524\n",
      "gpt2-xl, 8, squad, 0.5272435897435898\n",
      "gpt2-xl, 8, writing, 0.55\n",
      "gpt2-xl, 2, xsum, 0.588\n",
      "gpt2-xl, 2, squad, 0.6634615384615384\n",
      "gpt2-xl, 2, writing, 0.632\n",
      "gpt2-xl, 4, xsum, 0.553\n",
      "gpt2-xl, 4, squad, 0.6105769230769231\n",
      "gpt2-xl, 4, writing, 0.608\n",
      "gpt2-xl, 6, xsum, 0.544\n",
      "gpt2-xl, 6, squad, 0.5512820512820513\n",
      "gpt2-xl, 6, writing, 0.567\n",
      "EleutherAI_gpt-neo-2.7B, 8, xsum, 0.565\n",
      "EleutherAI_gpt-neo-2.7B, 8, squad, 0.5785256410256411\n",
      "EleutherAI_gpt-neo-2.7B, 8, writing, 0.564\n",
      "EleutherAI_gpt-neo-2.7B, 2, xsum, 0.617\n",
      "EleutherAI_gpt-neo-2.7B, 2, squad, 0.6105769230769231\n",
      "EleutherAI_gpt-neo-2.7B, 2, writing, 0.635\n",
      "EleutherAI_gpt-neo-2.7B, 4, xsum, 0.576\n",
      "EleutherAI_gpt-neo-2.7B, 4, squad, 0.6506410256410257\n",
      "EleutherAI_gpt-neo-2.7B, 4, writing, 0.587\n",
      "EleutherAI_gpt-neo-2.7B, 10, xsum, 0.56\n",
      "EleutherAI_gpt-neo-2.7B, 10, squad, 0.5881410256410257\n",
      "EleutherAI_gpt-neo-2.7B, 10, writing, 0.533\n",
      "EleutherAI_gpt-neo-2.7B, 6, xsum, 0.554\n",
      "EleutherAI_gpt-neo-2.7B, 6, squad, 0.5977564102564102\n",
      "EleutherAI_gpt-neo-2.7B, 6, writing, 0.572\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "path = \"results/fo\"\n",
    "for f in os.listdir(path):\n",
    "    source = f.split(\"-\")[0]\n",
    "    model = \"-\".join(f.split(\"-\")[:-4])\n",
    "    for sf in os.listdir(os.path.join(path, f)):\n",
    "        epoch = sf.split(\"-\")[-1]\n",
    "        for dataset in [\"xsum\", \"squad\", \"writing\"]:\n",
    "            with open(os.path.join(path, f, sf, dataset, \"perturbation_50_z_results.json\"), \"rb\") as file:\n",
    "                acc = json.load(file)[\"accuracy\"]\n",
    "            print(\", \".join([model, epoch, dataset, str(acc)]))\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
